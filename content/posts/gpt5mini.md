---
date: '2025-08-22T22:16:31Z'
draft: true
title: 'Gpt5mini'
showToc: true
---

# What even is GitHub Copilot

The way I understand it, the autocomplete in Copilot works by constantly feeding
your code to an LLM and asking it what it thinks should be added after the
cursor. 

In a decently sized project, a single file can be thousands of tokens. 
Constantly feeding that to an LLM, even with prompt caching results in
incredibly high token usage. 
However, GitHub recently announced that it will use GPT-4o as the default
autocomplete model. This thing is approximately 5x as expensive as GPT-4o-mini.
They announced this




Is GPT-5-mini the new GitHub Copilot base model?


If it is, then I'm worried. GPT-5 is better than 4.1, but even that is debatable. But GPT-5-mini as a replacement for it seems odd. 
GPT-4o is cheaper to run than 4.1 is. It seems the logical successor to 4.1
This doesn't feel like progress.
Real progress isn't a new product offering the same quality at the same price, with the option to pay exorbitant sums of money for a slightly better experience.
We know GPT-4o


